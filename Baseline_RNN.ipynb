{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLzDOuXNuLq4"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMI0NUFttmhl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, GRU, Input, Lambda\n",
        "from tensorflow.keras.layers import Dropout, LSTM, TimeDistributed, MaxPool2D, Reshape\n",
        "from sklearn.metrics         import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiTgrvjAwc2V"
      },
      "source": [
        "Connect your Google Drive. \n",
        "Since the files are quite big, it is much more convinient to upload them in a cloud service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaQIUzakwsco",
        "outputId": "a88ea8f0-f4d8-4c75-b199-740e064f232d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFqpc37DuWHs"
      },
      "source": [
        "Read prepared train-test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPSjexvnxWSE"
      },
      "outputs": [],
      "source": [
        "link_to_drive = '/content/drive/MyDrive/DL_Final_Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQfe0L_QuHaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a362e565-f018-4173-a67b-771aebbefede"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31367, 30, 30, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_val   = np.load(link_to_drive + 'X_val.npy')\n",
        "X_train = np.load(link_to_drive + 'X_train.npy')\n",
        "y_val   = np.load(link_to_drive + 'y_val.npy')\n",
        "y_train = np.load(link_to_drive + 'y_train.npy')\n",
        "X_test  = np.load(link_to_drive + 'X_test.npy')\n",
        "y_test  = pd.read_csv(link_to_drive + 'Test.csv')\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0baBDU5EyPVd"
      },
      "source": [
        "Build a Recurrent Neural Network (RNN)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255.0\n",
        "X_val = X_val/255.0\n",
        "X_test = X_test/255.0"
      ],
      "metadata": {
        "id": "nJ6NKyJArd7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 7\n",
        "batch_size = 64 \n",
        "loss_func = 'categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)"
      ],
      "metadata": {
        "id": "UPbMgdtDqE8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a624bda-d6e5-4f63-a170-a7eb95ddfdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ReshapeLayer(x):\n",
        "    shape = x.shape\n",
        "    reshape = Reshape((shape[1],shape[2]*shape[3]))(x)\n",
        "    return reshape"
      ],
      "metadata": {
        "id": "D2HK2Nwo4Quv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQVuWAU0umvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660ada05-c711-4a01-bd18-c54d570a30e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu',\n",
        "                                 input_shape=X_train.shape[1:]))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Lambda(ReshapeLayer))\n",
        "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "model.compile(loss=loss_func, optimizer=opt, metrics=metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUxh3mXLzhi7"
      },
      "source": [
        "Train the RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF_T_LyTx7Mm"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMFW1P9b4DUG"
      },
      "source": [
        "Plot the graphs for accuracy and loss of both datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzNnEPdNzuoz"
      },
      "outputs": [],
      "source": [
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy and Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig('accuracy_loss.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En6oB5Bz6K2-"
      },
      "source": [
        "Test the trained model with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdZF8AYc6TgQ"
      },
      "outputs": [],
      "source": [
        "predict_x=model.predict(X_test) \n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "\n",
        "labels = y_test['ClassId'].values\n",
        "print(accuracy_score(labels, classes_x))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Baseline_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}